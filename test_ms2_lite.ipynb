{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T05:19:33.091395021Z",
     "start_time": "2025-07-15T05:06:05.424718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Workflow: Concatenate BioIO time-series and save as lazy-loadable OME-Zarr\n",
    "\n",
    "from bioio import BioImage\n",
    "from bioio.writers import OmeZarrWriterV3\n",
    "import xarray as xr\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class TimeSeriesReader:\n",
    "    def __init__(self, folder_path: Union[str, Path], time_chunks: int = 10):\n",
    "        self.folder_path = Path(folder_path)\n",
    "        self.time_chunks = time_chunks\n",
    "        self.file_paths = sorted([str(p) for p in self.folder_path.glob(\"*\") if p.is_file()])\n",
    "        self.data_arrays = []\n",
    "        self.metadata_list = []\n",
    "        self.timestamps = []\n",
    "        self.total_frames = 0\n",
    "        self.combined = None\n",
    "        self.combined_metadata = {}\n",
    "\n",
    "    def load_data(self):\n",
    "        for path in self.file_paths:\n",
    "            img = BioImage(path)\n",
    "            da_xr = img.xarray_data\n",
    "            nT = da_xr.sizes.get(\"T\", 1)\n",
    "            self.total_frames += nT\n",
    "            self.data_arrays.append(da_xr)\n",
    "            self.metadata_list.append(img.metadata)\n",
    "\n",
    "            timestamps = getattr(img.metadata, \"timestamps\", None)\n",
    "            if timestamps is not None:\n",
    "                self.timestamps.extend(timestamps)\n",
    "            else:\n",
    "                self.timestamps.extend([None] * nT)\n",
    "\n",
    "    def concatenate_and_chunk(self):\n",
    "        self.combined = xr.concat(self.data_arrays, dim=\"T\")\n",
    "        frames_per_chunk = max(1, self.total_frames // self.time_chunks)\n",
    "        chunk_dict = {dim: 1 for dim in self.combined.dims if dim != \"T\"}\n",
    "        chunk_dict[\"T\"] = frames_per_chunk\n",
    "        self.combined = self.combined.chunk(chunk_dict)\n",
    "        self.combined = self.combined.assign_coords(T=(\"T\", self.timestamps))\n",
    "\n",
    "    def build_metadata(self):\n",
    "        self.combined_metadata = {\n",
    "            \"source_files\": self.file_paths,\n",
    "            \"concatenated_from\": len(self.file_paths),\n",
    "            \"original_metadata\": self.metadata_list,\n",
    "        }\n",
    "\n",
    "    def save_to_zarr(self, output_path: Union[str, Path]):\n",
    "        shape = tuple(self.combined.sizes[dim] for dim in self.combined.dims)\n",
    "        dtype = self.combined.dtype\n",
    "\n",
    "        # Attempt to retrieve physical pixel sizes from the first image's metadata\n",
    "        if self.metadata_list:\n",
    "            first_meta = self.metadata_list[0]\n",
    "            px_size_z = getattr(first_meta, \"physical_size_z\", 1.0)\n",
    "            px_size_y = getattr(first_meta, \"physical_size_y\", 1.0)\n",
    "            px_size_x = getattr(first_meta, \"physical_size_x\", 1.0)\n",
    "        else:\n",
    "            px_size_z = px_size_y = px_size_x = 1.0\n",
    "\n",
    "        # Match the scale factors to the axes: T, C, Z, Y, X\n",
    "        scale_factors = [1.0, 1.0, px_size_z, px_size_y, px_size_x]\n",
    "\n",
    "        writer = OmeZarrWriterV3(\n",
    "            store=str(output_path),\n",
    "            shape=shape,\n",
    "            dtype=dtype,\n",
    "            scale_factors=scale_factors,\n",
    "            axes_names=[\"T\", \"C\", \"Z\", \"Y\", \"X\"],\n",
    "        )\n",
    "        writer.write_image(\n",
    "            image=self.combined,\n",
    "            dimension_order=\"\".join(self.combined.dims),\n",
    "            metadata=self.combined_metadata,\n",
    "        )\n",
    "\n",
    "    def run(self, output_path: str):\n",
    "        self.load_data()\n",
    "        self.concatenate_and_chunk()\n",
    "        self.build_metadata()\n",
    "        self.save_to_zarr(output_path)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"/mnt/Data1/Yovan/physio2025/ms2_pipeline_lite/test_data/MCP-mSG_His-RFP_r1-close(002)_embryo02\"\n",
    "    concatenator = TimeSeriesReader(folder, time_chunks=20)\n",
    "    concatenator.run(\"/mnt/Data1/Yovan/physio2025/ms2_pipeline_lite/test_data/MCP-mSG_His-RFP_r1-close(002)_embryo02/collated_dataset.zarr\")\n",
    "\n",
    "    # Lazy load example\n",
    "    # import xarray as xr\n",
    "    # ds = xr.open_zarr(\"output_merged.zarr\", consolidated=True)\n",
    "    # data = ds[\"0\"]  # the group name \"0\" is the default dataset\n"
   ],
   "id": "7f09e96defd70ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d2a6b1cb862340a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "47a81e48ce320f65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
